{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LXGWy_n5dtQb"
   },
   "outputs": [],
   "source": [
    "#importing tensoflow\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4210,
     "status": "ok",
     "timestamp": 1566396831892,
     "user": {
      "displayName": "Vijay kumar kaushik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mABgWoMMRKnZWcIoo8yHgY_GLEgB0kCKutOtvtjSg=s64",
      "userId": "00733964334759881308"
     },
     "user_tz": -330
    },
    "id": "GNw3VzSXd-LJ",
    "outputId": "575df8aa-7f63-4d94-e160-7b84d9988efc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-4016d935df64>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\VJ\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\VJ\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_DATA/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\VJ\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_DATA/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\VJ\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_DATA/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_DATA/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\VJ\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "#importing Data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_DATA/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "igQGAEvAhpeY"
   },
   "outputs": [],
   "source": [
    "#initialising contants according our decided architecture of CNN\n",
    "input_width = 28 #input image width\n",
    "input_height = 28 #input image height\n",
    "input_channels = 1 # No of Channels of input image\n",
    "input_pixels = 784 # product of input image height and input image width\n",
    "\n",
    "n_conv1 = 32 # no of cnn units in 1st Convolution layer\n",
    "n_conv2 = 64 # no of cnn units int 2nd Convolution layer\n",
    "\n",
    "stride_conv1 = 1 #Stride of filter in 1st Convolution layer\n",
    "stride_conv2 = 1 # Stride of filter in 2nd Convolution layer\n",
    "\n",
    "conv1_k = 5 # Dimension of Square filter in 1st Convoltuion layer\n",
    "conv2_k = 5 # Dimension of Square filter in 2nd Convolution layer\n",
    "\n",
    "max_pool1_k = 2 # Dimension of filter in 1 pooling layer\n",
    "max_pool2_k = 2 # Dimension of filter in 2nd pooling layer\n",
    "\n",
    "n_hidden = 1024 # No of units in hidden layer \n",
    "n_out = 10 # No of output unit, which is equal no of labels in the data\n",
    "\n",
    "input_size_to_hidden = (input_width//(max_pool1_k*max_pool2_k)) * (input_height//(max_pool1_k*max_pool2_k)) *n_conv2  # no of units of input to the hidden layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kAW5QgqjhwZQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\VJ\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#initialising random weights and biases to all the filters and hidden layer\n",
    "\n",
    "weights = {\n",
    "    \"wc1\" : tf.Variable(tf.random_normal([conv1_k, conv1_k, input_channels, n_conv1])),\n",
    "    \"wc2\" : tf.Variable(tf.random_normal([conv2_k, conv2_k, n_conv1, n_conv2])),\n",
    "    \"wh1\" : tf.Variable(tf.random_normal([input_size_to_hidden, n_hidden])),\n",
    "    \"wo\" : tf.Variable(tf.random_normal([n_hidden, n_out]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    \"bc1\" : tf.Variable(tf.random_normal([n_conv1])),\n",
    "    \"bc2\" : tf.Variable(tf.random_normal([n_conv2])),\n",
    "    \"bh1\" : tf.Variable(tf.random_normal([n_hidden])),\n",
    "    \"bo\" : tf.Variable(tf.random_normal([n_out])),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "np8vwJUckOP9"
   },
   "outputs": [],
   "source": [
    "# Conv function which return output after each convolution operation in the neural net\n",
    "\n",
    "def conv(x, weights, bias, strides = 1):\n",
    "    out = tf.nn.conv2d(x, weights, padding=\"SAME\", strides = [1, strides, strides, 1])\n",
    "    out = tf.nn.bias_add(out, bias)\n",
    "    out = tf.nn.relu(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NhfViTD6kgNe"
   },
   "outputs": [],
   "source": [
    "# maxpooling function which will return output after each pooling (max) operation in the neural net\n",
    "def maxpooling(x, k = 2):\n",
    "    return tf.nn.max_pool(x, padding = \"SAME\", ksize = [1, k, k, 1], strides = [1, k, k, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D7Xf4eX0kxBy"
   },
   "outputs": [],
   "source": [
    "# cnn funtion is the function which forward propogate the input through the convolution and pooling layers as per the decided architecture\n",
    "\n",
    "def cnn(x, weights, biases, keep_prob):\n",
    "    x = tf.reshape(x, shape = [-1 ,input_height, input_width, input_channels]) #reshaping the input data point to desired dimensions \n",
    "    \n",
    "    #passing data through 1st convolution layer\n",
    "    conv1 = conv(x, weights['wc1'], biases['bc1'], stride_conv1)\n",
    "    #passing data through 1st pooling layer\n",
    "    conv1_pool = maxpooling(conv1, max_pool1_k)\n",
    "    \n",
    "    \n",
    "    #passing data through 2nd convolution layer\n",
    "    conv2 = conv(conv1_pool, weights['wc2'], biases['bc2'], stride_conv2)\n",
    "    #passing data through 2nd pooling layer\n",
    "    conv2_pool = maxpooling(conv2, max_pool2_k)\n",
    "    \n",
    "    #reshaping the output of 2nd pooling layer as the hidden layer requirement\n",
    "    hidden_input = tf.reshape(conv2_pool, shape = [-1, input_size_to_hidden])\n",
    "    \n",
    "    #multiplying with weights and adding biases without passing it into activation function\n",
    "    hidden_output_before_activation = tf.add(tf.matmul(hidden_input, weights['wh1']), biases['bh1'])\n",
    "    \n",
    "    #output of hidden layer after applying activation function\n",
    "    hidden_output_before_dropout = tf.nn.relu(hidden_output_before_activation)\n",
    "    \n",
    "    #final output of hidden layer after adding dropout layer in order to avoid overfitting\n",
    "    hidden_output = tf.nn.dropout(hidden_output_before_dropout, keep_prob) \n",
    "   \n",
    "    #final output of the neural net\n",
    "    output = tf.add(tf.matmul(hidden_output, weights['wo']), biases['bo'])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1158,
     "status": "ok",
     "timestamp": 1566398351485,
     "user": {
      "displayName": "Vijay kumar kaushik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mABgWoMMRKnZWcIoo8yHgY_GLEgB0kCKutOtvtjSg=s64",
      "userId": "00733964334759881308"
     },
     "user_tz": -330
    },
    "id": "Mu9acDZVlwP1",
    "outputId": "5c959330-a344-493c-eef9-a1507677b4f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-0fb5caae65c4>:27: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "#defining placeholders for holding the input data and passing it into neural net\n",
    "\n",
    "x = tf.placeholder(\"float\", [None, input_pixels])\n",
    "y = tf.placeholder(tf.int32, [None, n_out])\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "\n",
    "#calling cnn to get output from neural net but this does not gives the final output, for final output we need to run a session\n",
    "pred = cnn(x, weights, biases, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h2uUXrlingOJ"
   },
   "outputs": [],
   "source": [
    "#calculating the cost which is measure of how much our predicted labels are different from actual labels\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred, labels = y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Es-VGz4hn8cX"
   },
   "outputs": [],
   "source": [
    "# defining the optimizer which will backpropogate and reset weights of out neural net in order to minimise cost and having better predictions\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "optimize = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Qz_e746oPEV"
   },
   "outputs": [],
   "source": [
    "# initialing a session and initialing all the variables which are defined above\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3179707,
     "status": "ok",
     "timestamp": 1566402195837,
     "user": {
      "displayName": "Vijay kumar kaushik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mABgWoMMRKnZWcIoo8yHgY_GLEgB0kCKutOtvtjSg=s64",
      "userId": "00733964334759881308"
     },
     "user_tz": -330
    },
    "id": "VMHZfVhEoc2B",
    "outputId": "b0a26836-641a-47fb-ebe7-e39ac3812302"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1  completed\n",
      "epoch  2  completed\n",
      "epoch  3  completed\n",
      "epoch  4  completed\n",
      "epoch  5  completed\n",
      "epoch  6  completed\n",
      "epoch  7  completed\n",
      "epoch  8  completed\n",
      "epoch  9  completed\n",
      "epoch  10  completed\n",
      "epoch  11  completed\n",
      "epoch  12  completed\n",
      "epoch  13  completed\n",
      "epoch  14  completed\n",
      "epoch  15  completed\n",
      "epoch  16  completed\n",
      "epoch  17  completed\n",
      "epoch  18  completed\n",
      "epoch  19  completed\n",
      "epoch  20  completed\n"
     ]
    }
   ],
   "source": [
    "#Running the epochs and session over neural net \n",
    "batch_size = 100\n",
    "for i in range(20): # no of epochs\n",
    "    num_batches = int(mnist.train.num_examples/batch_size)\n",
    "    total_cost = 0\n",
    "    for j in range(num_batches):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        c, _ = sess.run([cost,optimize], feed_dict={x:batch_x , y:batch_y, keep_prob:0.8})\n",
    "        total_cost += c\n",
    "    print(\"epoch \", i+1, \" completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6378,
     "status": "ok",
     "timestamp": 1566402265369,
     "user": {
      "displayName": "Vijay kumar kaushik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mABgWoMMRKnZWcIoo8yHgY_GLEgB0kCKutOtvtjSg=s64",
      "userId": "00733964334759881308"
     },
     "user_tz": -330
    },
    "id": "Kwr4lt1ZpLCg",
    "outputId": "0633cc00-2276-4af7-b463-cb9cc4404523"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted correctlty  9859  out of  10000\n"
     ]
    }
   ],
   "source": [
    "#Getting the prediction from the trained neural net\n",
    "predictions = tf.argmax(pred, 1)\n",
    "\n",
    "#getting the actual label \n",
    "correct_labels = tf.argmax(y, 1)\n",
    "\n",
    "#counting correct prediction from the model\n",
    "correct_predictions = tf.equal(predictions, correct_labels)\n",
    "\n",
    "#appling the above functions inside session\n",
    "predictions,correct_preds  = sess.run([predictions, correct_predictions], feed_dict={x:mnist.test.images,\n",
    "                                              y:mnist.test.labels, keep_prob:1.0})\n",
    "\n",
    "print(\"Predicted correctlty \",correct_preds.sum(), \" out of \", len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JqFw40Ng2MgS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MNIST_CNN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
